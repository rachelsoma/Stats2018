---
output:
  pdf_document: default
  html_document: default
  word_document: default
---
Cover Sheet
========================================================


By including this statement, we, all the students listed in the table
below, declare that:

- We hold a copy of this assignment if the original is lost or damaged.

- We hereby certify that no part of this assignment has been copied from
  any other student's work or from any other source except where due
  acknowledgement is made in the assignment.

- No part of the assignment has been written for us by any other person
  except where collaboration has been authorised by the unit coordinator.

- We are aware that this work may be reproduced and submitted to plagiarism
  detection software programs for the purpose of detecting possible
  plagiarism; this software may retain a copy on its database for future
  plagiarism checking.

- We hereby certify that no part of this assignment or product has been
  submitted by any of us in another (previous or current) assessment, except
  where appropriately referenced, and with prior permission from the unit
  coordinator for this unit.

- We hereby certify that we have read and understand what the University
  considers to be academic misconduct, and that we are aware of the
  penalties that may be imposed for academic misconduct.

Name               | Student Number | Contribution (%)
-------------------|----------------|-----------------
Rachel Hardie      |18820821        |
Dylan Wang         |18998014        |
Bradley McInerney  |19029900        |
                   |                |

<div style="page-break-before:always;"></div>


Group Project
========================================================

This Group Project analyses hard drive reliability data.
The file HardDisks.csv contains the following information for 125864 hard drives:
(1) a unique serial number;
(2) the model of the hard drive;
(3) the number of days the hard drive was operational;
(4) the mean operating temperature of the drive; and
(5) whether the hard drive was removed because it had failed.
A drive that is listed as not having failed either was still operational at the end of the data collection period, or it was
removed for other reasons, for instance a capacity upgrade.


```{r}
#Import drives data set
drives = read.csv("HardDisks.csv",header=TRUE) #Load a dataset from .csv file
attach(drives)

#Check if serial_number in indeed unique
n_occur <- data.frame(table(serial_number))
n_occur[n_occur$Freq > 1,]  
#As there are 0 rows that appear twice then it is confirmed unique in this set
```

Part One - Proportion of drives that fail early
--------------------------------------------------------

We want to investigate the proportion of drives that fail in the first year of operation.
(a) [1 mark] Create a subset of the cases that is relevant for this analysis and print the number of cases in that subset.

```{r}
n=nrow(drives)#total number of cases

drives.failed=which(failed=="TRUE") #subset of cases that failed
n.drives.failed=length(drives.failed)

drives.failed.y1=which(failed=="TRUE" & days < 366) #subset of cases that filed in first year
n.drives.failed.y1=length(drives.failed.y1) #number of cases in subset

paste(length(drives.failed.y1),"drives have failed in their first year")



#Create binomial data for cases that fail in the first year, this makes generating the boostrap much faster
failedY1.binom = rep(NA, n)
for (row in 1:n){
  if(drives[row, "days"]<366 & drives[row, "failed"]==TRUE){ #If they failed when they were under a year old add a 1, else 0, to make is a bonomial
    failedY1.binom[row] = 1
  }else{
    failedY1.binom[row] = 0
  }
}
```
(b) [1 mark] Compute a point estimate for the proportion of drives that fail in the first year of operation.

```{r}
phat=n.drives.failed.y1/n
paste("The probability of drives that fail in the first year is",phat, "(or", phat*100,"%)")
```


(c) [2 marks] Use bootstrapping to compute a 99% confidence interval for the proportion of drives that fail in the first
year of operation

```{r}

##Generating a Bootstrap Distribution
b = 1000 #number of bootstrap statistics
boot.dist = rep(NA, b)
for (i in 1:b) {
  boot.sample = sample(failedY1.binom, replace=TRUE)
  boot.dist[i] = sum(boot.sample)/length(boot.sample) #As we are testing for proportion
}
hist(boot.dist)
```

```{r}
CI = quantile(boot.dist, c(0.005,0.995)) #Quartiles for a 99% CI
cat("The 99% confidence interval for the proportion of drives that fail in the first year of operation is", CI[1], CI[2])
```

Part 2 Temperature and time to failure
--------------------------------------------------------

For this part, we only consider the drives that failed. We want to analyse whether the mean operating temperature of
the drive and the time to failure of the drive are associated.

(a) [1 mark] Compute and interpret the correlation between the mean operating temperature and the number of days until failure.
```{r}
failed.meantemp=meantemp[drives.failed]
failed.days=days[drives.failed]

cor.test(failed.meantemp,failed.days)
```

(b) [2 marks] Use randomisation to test at a significance level of 5% whether there is evidence that a higher mean op-
erating temperature is associated to earlier failure.
```{r}
#paired t-test

t.test(failed.days, 
       failed.meantemp, 
       paired=TRUE, 
       conf.level=0.95)


pairs(failed.days ~ failed.meantemp)

smoothScatter(failed.days, failed.meantemp,
     pch = ".",
     xlab="Days until failure",
     ylab="mean temperature")

abline(0,1, col="blue", lwd=2)

```

(c) [1 mark] Interpret your findings, comparing the results from parts (a) and (b). Discuss, in particular, whether
there is evidence that a higher operating temperature causes drives to fail earlier.



Part 3 Three 2TB drive models
--------------------------------------------------------
For this part, we only consider 2TB drives with the following model identifiers: 
"Hitachi HDS723020BLA642"
"ST320005XXXX" (Seagate)
"WDC WD20EFRX" (Western Digital)

(a) [2 marks] At a significance level of 1%, test whether there is evidence for a difference in the mean operating temperature between the three drive models and conduct a pairwise t-test.
Discuss your findings. Be specific about any differences between the models that can be inferred from the data.
```{r}
#Hypothisis test
#H0: The mean of the mean operating temperatures of all 3 tested drives will be the same
#HA: The mean of the mean operating temperatures for atleast 1 tested drive with differ from the others

#subsetting data
P = drives[,"meantemp"] #The data the subsets came from
mt1=drives[model=="Hitachi HDS723020BLA642", "meantemp"]
mt2=drives[model=="ST320005XXXX",            "meantemp"]
mt3=drives[model=="WDC WD20EFRX",            "meantemp"]

cat("Using an F-distribution to compute p-values requires all data that the subsets came from being normally distributed and all populations having the same variance.\n")
hist(P, breaks=100)
cat("Via a histogram of the data the subsets came from, we can assume it is normally distributed")
cat("As all pf the data that the subsets came from is the same set AND the sample standard deviations(", sd(mt1), sd(mt2), sd(mt3), ") differ by less then factors of 2, we can assume that the population variances are the same.\n")

MT = c(mt1, mt2, mt3) #combined set
N=length(MT) #length of combined set
k = 3 #number of groups

SST=(N-1)*sd(MT)^2
SSE=(length(mt1)-1)*sd(mt1)^2 + (length(mt2)-1)*sd(mt2)^2 + (length(mt3)-1)*sd(mt3)^2
SSG=SST-SSE
fstat = ((SSG/(k-1)) / (SSE/(N-k)))

pval=pf(fstat,k-1,N-k,lower.tail=FALSE)
#print(pval)

cat("At a signifigance level of 1% (0.01) and a p-value of", pval, ", as the p value is greater than the our signifigance level, we do not reject the null hypothisis 'there is no difference in mean operating temperatures between the 3 tested divice models'. So there is statistical evidence on a 1% signifigance that there is no difference in mean operating temperatures between the 3 tested divice models.\n")

#Pairwise T-test
MT.df = drives[model=="Hitachi HDS723020BLA642" | model=="ST320005XXXX" | model=="WDC WD20EFRX", ] #get MT but as a dataframe
pairwise.t.test(MT.df$meantemp, MT.df$model) #Use a paired t test to see the individual differences
```

Discussion:
- This whole test is under the assumption that the 3 chosen models only come in (or are only recoded in) 2TB versions as there is no data in the data frame to determine the sizes of the drives.
- The sizes in subsets for each drive varied greatly with the subset lengths: 11, 18, 167".
- The pairwise t-test shows that the higest difference in means was between the models 'WDC WD20EFRX' and 'ST320005XXXX'
- It also shows that the lowest was between 'Hitachi HDS723020BLA642' and 'WDC WD20EFRX'."
      

(b) [3 marks] At a significance level of 1%, test whether there is evidence for a difference in the proportion of failed
drives between the three drive models. Discuss your findings. Be specific about any differences between the models that can be inferred from the data.
```{r}
#Hypothesis test
#H0: The proportion of failed drives of all 3 tested drives will be the same
#HA: The proportion of failed drives for atleast 1 tested drive with differ from the othersC

#Get the proportion of each value
m1    = drives[model=="Hitachi HDS723020BLA642", ]  #Get the subset of each specific model to be tested
m1.ft = nrow(m1[m1$failed=="TRUE" & m1$days<366, ]) #Get the number of drives where failed=TRUE  from the model
m1.ff = nrow(m1)-m1.ft                              #Get the number of drives where failed=FALSE from the model

m2    = drives[model=="ST320005XXXX", ] 
m2.ft = nrow(m2[m2$failed=="TRUE" & m2$days<366, ])
m2.ff = nrow(m2)-m2.ft 

m3    = drives[model=="WDC WD20EFRX", ] 
m3.ft = nrow(m3[m3$failed=="TRUE" & m3$days<366, ])
m3.ff = nrow(m3)-m3.ft

#Create a matrix of the data
values.obv = matrix(c(m1.ft, m1.ff,
                      m2.ft, m2.ff,
                      m3.ft, m3.ff),
                    ncol=2, byrow=TRUE)

#Display matrix
colnames(values.obv) = c("failed", "didn't fail")
rownames(values.obv) = c("Hitachi HDS723020BLA642", "ST320005XXXX", "WDC WD20EFRX")
print(values.obv)

#Calculate P-value
print(chisq.test(values.obv))
print("As R gives us a warning about the aproximation, one of the expected values must be less than five and we should simulate the p value with a randomisation distrobution by using simulate.p.value=TRUE")

print(chisq.test(values.obv, simulate.p.value=TRUE))
```

As the p-value (0.0004998) is under the 0.01 significance level, the null hypothesis is rejected.

Discussion:
- This whole test is under the assumption that the 3 chosen models only come in (or are only recoded in) 2TB versions as there is no data in the data frame to determine the sizes of the drives.
- The sizes in subsets for each drive varied greatly with the subset lengths: 11, 18, 167".
- Model "ST320005XXXX" has the highest proportion of divices that failed in the first year
- Model "WDC WD20EFRX" has the lowest proportion of divices that failed in the first year and that may be why, out of the three testest models, many more drives of this model were recoreded as being used.



The end

```{r}
#leave this as the last chunk
detach(drives)
```
